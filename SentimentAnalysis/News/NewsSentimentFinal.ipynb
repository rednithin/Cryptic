{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for Loading Custom Dataset using TorchText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import re\n",
    "from torchtext import data\n",
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc='Progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use BucketIterator that is provided by TorchText, it returns a Batch object. Instead we can do two things : \n",
    "1. Write extra code in the training loop\n",
    "2. Write iterable wrapper around batch Object from which we can get desired data.\n",
    "\n",
    "BatchGenerator does (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field):\n",
    "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            yield (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "This is the tokenizer used by torchtext for doing preprocessing on the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s): \n",
    "    return [w.lower() for w in tweet_clean(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "This is called within the tokenizer to remove unnecessary aspects from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric character\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text)\n",
    "    # re.sub(r'https?:/\\/\\S+', ' ', text) # remove links\n",
    "#     text = text.replace(',',';')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainDS(valid):\n",
    "#     valid = 'Bitcoin'\n",
    "    result = pd.DataFrame()\n",
    "    fields = ['Article','Label']\n",
    "    file_dict = {'Altcoin':'newsAltcoin.tsv','Binance':'newsBinance.tsv','Bitcoin':'newsBitcoin.tsv','Blockchain':'newsBlockchain.tsv','CoinBase':'newsCoinBase.tsv','Ethereum':'newsEth.tsv','ICO':'newsICO.tsv','Litecoin':'newsLitecoin.tsv','Mining':'newsMining.tsv','Poloniex':'newsPoloniex.tsv','Satoshi':'newsSatoshi.tsv','Wallet':'newsWallet.tsv'}\n",
    "    valid_file = \"/home/nithin/Git/Cryptic/SentimentAnalysis/News/TSV/\"+file_dict[valid]\n",
    "    train_file = \"/home/nithin/Git/Cryptic/SentimentAnalysis/News/TSV/NewsTrain.tsv\"\n",
    "    for i in file_dict:\n",
    "        df = pd.DataFrame()\n",
    "        if(i!=valid):\n",
    "            df = pd.read_csv(\"/home/nithin/Git/Cryptic/SentimentAnalysis/News/TSV/\"+file_dict[i], sep = '\\t', usecols = fields)\n",
    "            if(result.empty):\n",
    "                result = df\n",
    "            else:\n",
    "                result = pd.merge(result, df, how = \"outer\", on = fields)\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(valid_file, sep = '\\t', usecols = fields)\n",
    "    result = pd.merge(result, df, how = \"left\", on = fields)\n",
    "    result.to_csv(train_file, sep = '\\t', header = fields, index = False)\n",
    "    return train_file, valid_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field = data.Field(sequential=True, \n",
    "                       # tokenize=tokenizer, \n",
    "                       include_lengths=True, \n",
    "                       use_vocab=True)\n",
    "label_field = data.Field(sequential=False, \n",
    "                             use_vocab=False, \n",
    "                             pad_token=None, \n",
    "                             unk_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DefTrainValid(train_file,valid_File):\n",
    "    train_val_fields = [\n",
    "        ('Article', txt_field), # process it as text\n",
    "        ('Label', label_field) # process it as label\n",
    "    ]\n",
    "    trainds, valds = data.TabularDataset.splits(path='/home/nithin/Git/Cryptic/SentimentAnalysis/News/TSV', \n",
    "                                            format='tsv', \n",
    "                                            train=train_file, \n",
    "                                            validation=valid_File, \n",
    "                                            fields=train_val_fields, \n",
    "skip_header=True)\n",
    "    return trainds, valds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the capital amount from Trading Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capital value is hardcoded right now. If the customer wants to trade x units of currency A for currency B, convert x of A into dollars and use this value as capital.\n",
    "\n",
    "curr1 and curr2 are full names of currencies. If shortforms are used, change key values in file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewsSentimentAnalysis(curr1,curr2):\n",
    "#     capital = unitsOfCurr1 * usdExchangeValue\n",
    "    capital = curr1 * 50 \n",
    "    valid = curr2 \n",
    "    train_file, valid_file = CreateTrainDS(valid)\n",
    "    trainds, valds = DefTrainValid(train_file, valid_file)\n",
    "    vec = vocab.Vectors('glove.twitter.27B.100d.txt', '/home/nithin/Git/Cryptic/GloVe-1.2')\n",
    "    txt_field.build_vocab(trainds, valds, max_size=200000, vectors=vec)\n",
    "    label_field.build_vocab(trainds)\n",
    "    traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), \n",
    "                                            batch_sizes=(512,1024), \n",
    "                                            sort_key=lambda x: len(x.Article), \n",
    "                                            device=-1, \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False)\n",
    "    train_batch_it = BatchGenerator(traindl, 'Article', 'Label') # use the wrapper to convert Batch to data\n",
    "    val_batch_it = BatchGenerator(valdl, 'Article', 'Label')\n",
    "    \n",
    "    vocab_size = len(txt_field.vocab)\n",
    "    embedding_dim = 100\n",
    "    n_hidden = 64\n",
    "    n_out = 3\n",
    "\n",
    "    m = SimpleGRU(vocab_size, embedding_dim, n_hidden, n_out, trainds.fields['Article'].vocab.vectors)\n",
    "    opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n",
    "\n",
    "    fit(capital, model=m, train_dl=train_batch_it, val_dl=val_batch_it, loss_fn=F.nll_loss, opt=opt, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU and ConcatPooling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.embedding_dim,self.n_hidden,self.n_out,self.bidirectional = vocab_size, embedding_dim, n_hidden, n_out, bidirectional\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb.weight.data.copy_(pretrained_vec)\n",
    "        self.emb.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(self.n_hidden, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1) # batch size\n",
    "        seq = seq.transpose(0,1)\n",
    "        self.h = self.init_hidden(bs) # initialize hidden state of GRU\n",
    "        embs = self.emb(seq)\n",
    "        embs = embs.transpose(0,1)\n",
    "        embs = pack_padded_sequence(embs, lengths) # unpad\n",
    "        gru_out, self.h = self.gru(embs, self.h) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out) # pad the sequence to the max length in the batch\n",
    "        # since it is as classification problem, we will grab the last hidden state\n",
    "        outp = self.out(self.h[-1]) # self.h[-1] contains hidden state of last timestep\n",
    "#         return F.log_softmax(outp, dim=-1)\n",
    "        return F.log_softmax(outp)\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        if self.bidirectional:\n",
    "            return torch.zeros((2,batch_size,self.n_hidden))\n",
    "        else:\n",
    "            return torch.zeros((1,batch_size,self.n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatPoolingGRUAdaptive(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb.weight.data.copy_(pretrained_vec) # load pretrained vectors\n",
    "        self.emb.weight.requires_grad = False # make embedding non trainable\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            self.out = nn.Linear(self.n_hidden*2*2, self.n_out)\n",
    "        else:\n",
    "            self.out = nn.Linear(self.n_hidden*2, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1)\n",
    "        self.h = self.init_hidden(bs)\n",
    "        seq = seq.transpose(0,1)\n",
    "        embs = self.emb(seq)\n",
    "        embs = embs.transpose(0,1)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)        \n",
    "        \n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)        \n",
    "        outp = self.out(torch.cat([avg_pool,max_pool],dim=1))\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        if self.bidirectional:\n",
    "            return torch.zeros((2,batch_size,self.n_hidden))\n",
    "        else:\n",
    "            return torch.zeros((1,batch_size,self.n_hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(capital, model, train_dl, val_dl, loss_fn, opt, epochs=3):\n",
    "    num_batch = len(train_dl)\n",
    "    senti_dict = {}\n",
    "    \n",
    "    for epoch in tnrange(epochs):      \n",
    "        y_true_train = list()\n",
    "        y_pred_train = list()\n",
    "        total_loss_train = 0          \n",
    "        \n",
    "        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "        for (X,lengths),y in t:\n",
    "            t.set_description(\"Epoch {0}\".format(epoch))\n",
    "            lengths = lengths.cpu().numpy()\n",
    "                \n",
    "            opt.zero_grad()\n",
    "            pred = model(X, lengths)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item())\n",
    "            pred_idx = torch.max(pred, dim=1)[1]\n",
    "            \n",
    "            y_true_train += list(y.cpu().data.numpy())\n",
    "            y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "            total_loss_train += loss.item()\n",
    "            \n",
    "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        \n",
    "        if val_dl:\n",
    "            y_true_val = list()\n",
    "            y_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            for (X,lengths),y in tqdm_notebook(val_dl, leave=False):\n",
    "                pred = model(X, lengths.cpu().numpy())\n",
    "                loss = loss_fn(pred, y)\n",
    "                pred_idx = torch.max(pred, 1)[1]\n",
    "                y_true_val += list(y.cpu().data.numpy())\n",
    "                y_pred_val += list(pred_idx.cpu().data.numpy())\n",
    "                total_loss_val += loss.item()\n",
    "            valacc = accuracy_score(y_true_val, y_pred_val)\n",
    "            valloss = total_loss_val/len(val_dl)\n",
    "            y4senti = [i for i in y_pred_val if i!=1]\n",
    "            avg_senti = np.mean(y4senti)\n",
    "            if(math.isnan(avg_senti)):\n",
    "                avg_senti = 1.0\n",
    "            senti_dict[valacc] = avg_senti\n",
    "            \n",
    "            if(avg_senti<1.0):\n",
    "                new_amt = (avg_senti/2)*capital\n",
    "            elif(avg_senti==1.0):\n",
    "                new_amt = .5 * capital\n",
    "            else:\n",
    "                new_amt = (.5+((avg_senti - 1)/2))*capital\n",
    "            print(\"Epoch {0}: train_loss: {1:.4f} train_acc: {2:.4f} | val_loss: {3:.4f} val_acc: {4:.4f} avg_senti: {5:.4}\".format(epoch,train_loss,train_acc,valloss,valacc,avg_senti))\n",
    "            print(\"Original Capital : {0} New Capital : {1}\".format(capital,new_amt))\n",
    "        else:\n",
    "            print(\"Epoch {0}: train_loss: {1:.4f} train_acc: {2:.4f}\".format(epoch,train_loss,train_acc))\n",
    "    if(val_dl):\n",
    "        print(\"\\nMaximum accuracy and corresponding sentiment : \", max(senti_dict), senti_dict[max(senti_dict)])\n",
    "        if(avg_senti<1.0):\n",
    "                new_amt = (avg_senti/2)*capital\n",
    "                final_senti = 0 + ((avg_senti)/2)*100\n",
    "        elif(avg_senti==1.0):\n",
    "            new_amt = .5 * capital\n",
    "            final_senti = 50\n",
    "        else:\n",
    "            new_amt = (.5+((avg_senti - 1)/2))*capital\n",
    "            final_senti = 50 + ((avg_senti-1)/2)*100\n",
    "        print(\"Original Capital : {0} New Capital : {1}\".format(capital,new_amt))\n",
    "        print(\"Final Sentiment : \",final_senti)\n",
    "        return final_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533e9e6c45294a378cc387cc12b631b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 1.1267 train_acc: 0.1176 | val_loss: 1.0252 val_acc: 0.4615 avg_senti: 0.0\n",
      "Original Capital : 2500 New Capital : 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 1.0660 train_acc: 0.3908 | val_loss: 0.9697 val_acc: 0.6923 avg_senti: 0.0\n",
      "Original Capital : 2500 New Capital : 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss: 1.0102 train_acc: 0.6807 | val_loss: 0.9184 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss: 0.9590 train_acc: 0.7605 | val_loss: 0.8712 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss: 0.9121 train_acc: 0.7899 | val_loss: 0.8278 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss: 0.8694 train_acc: 0.7983 | val_loss: 0.7881 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss: 0.8307 train_acc: 0.7983 | val_loss: 0.7518 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss: 0.7957 train_acc: 0.7983 | val_loss: 0.7190 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss: 0.7644 train_acc: 0.7983 | val_loss: 0.6894 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss: 0.7366 train_acc: 0.7983 | val_loss: 0.6631 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss: 0.7123 train_acc: 0.7983 | val_loss: 0.6400 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss: 0.6913 train_acc: 0.7983 | val_loss: 0.6202 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss: 0.6736 train_acc: 0.7983 | val_loss: 0.6034 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss: 0.6591 train_acc: 0.7983 | val_loss: 0.5898 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss: 0.6475 train_acc: 0.7983 | val_loss: 0.5790 val_acc: 0.8462 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n",
      "\n",
      "\n",
      "Maximum accuracy and corresponding sentiment :  0.8461538461538461 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n",
      "Final Sentiment :  50\n"
     ]
    }
   ],
   "source": [
    "finalSentiment = NewsSentimentAnalysis(50,\"Altcoin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
