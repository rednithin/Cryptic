{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for Loading Custom Dataset using TorchText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import re\n",
    "from torchtext import data\n",
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc='Progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use BucketIterator that is provided by TorchText, it returns a Batch object. Instead we can do two things : \n",
    "1. Write extra code in the training loop\n",
    "2. Write iterable wrapper around batch Object from which we can get desired data.\n",
    "\n",
    "BatchGenerator does (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl, x_field, y_field):\n",
    "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x_field)\n",
    "            y = getattr(batch, self.y_field)\n",
    "            yield (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "This is the tokenizer used by torchtext for doing preprocessing on the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s): \n",
    "    return [w.lower() for w in tweet_clean(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "This is called within the tokenizer to remove unnecessary aspects from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric character\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text)\n",
    "    # re.sub(r'https?:/\\/\\S+', ' ', text) # remove links\n",
    "    text = text.replace(',',';')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainDS(valid):\n",
    "#     valid = 'Bitcoin'\n",
    "    result = pd.DataFrame()\n",
    "    fields = ['Tweet','Label']\n",
    "    file_dict = {'Altcoin':'TwitterAltcoin25Apr.tsv','Bitcoin':'TwitterBitcoinFrom7AprTrainTry1.tsv','Ethereum':'TwitterEthereum25Apr.tsv','Litecoin':'TwitterLitecoinTill7Apr.tsv'}\n",
    "    if(valid!=\"Bitcoin\"):\n",
    "        valid_file = \"/home/nithin/Git/Cryptic/SentimentAnalysis/Twitter/\"+file_dict[valid]\n",
    "    else:\n",
    "        valid_file = \"/home/nithin/Git/Cryptic/SentimentAnalysis/Twitter/TwitterBitcoinFrom7AprValidTry1.tsv\"\n",
    "    train_file = \"/home/nithin/Git/Cryptic/SentimentAnalysis/Twitter/TwitterTrain.tsv\"\n",
    "    for i in file_dict:\n",
    "        df = pd.DataFrame()\n",
    "        if(valid =='Bitcoin' or i!=valid):\n",
    "            df = pd.read_csv(\"/home/nithin/Git/Cryptic/SentimentAnalysis/Twitter/\"+file_dict[i], sep = '\\t', usecols = fields)\n",
    "            if(result.empty):\n",
    "                result = df\n",
    "            else:\n",
    "                result = pd.merge(result, df, how = \"outer\", on = fields)\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(valid_file, sep = '\\t', usecols = fields)\n",
    "    result = pd.merge(result, df, how = \"left\", on = fields)\n",
    "    result.drop_duplicates(keep = \"first\",inplace=True)\n",
    "    result.to_csv(train_file, sep = '\\t', header = fields, index = False)\n",
    "    return train_file, valid_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field = data.Field(sequential=True, \n",
    "                       # tokenize=tokenizer, \n",
    "                       include_lengths=True, \n",
    "                       use_vocab=True)\n",
    "label_field = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                         unk_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DefTrainValid(train_file, valid_file):\n",
    "    train_val_fields = [\n",
    "        ('Tweet', txt_field), # process it as text\n",
    "        ('Label', label_field) # process it as label\n",
    "    ]\n",
    "    trainds, valds = data.TabularDataset.splits(path='/home/nithin/Git/Cryptic/SentimentAnalysis/Twitter', \n",
    "                                                format='tsv', \n",
    "                                                train=train_file, \n",
    "                                                validation=valid_file, \n",
    "                                                fields=train_val_fields, \n",
    "    skip_header=True)\n",
    "    return trainds, valds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the capital amount from Trading Pair\n",
    "\n",
    "Capital value is hardcoded right now. If the customer wants to trade x units of currency A for currency B, convert x of A into dollars and use this value as capital.\n",
    "\n",
    "curr1 is the number of units of currency A and curr2 is the full name of B. If shortforms are used, change key values in file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwitterSentimentAnalysis(curr1,curr2):\n",
    "#     capital = unitsOfCurr1 * usdExchangeValue\n",
    "    capital = curr1 * 50 \n",
    "    valid = curr2 \n",
    "    train_file, valid_file = CreateTrainDS(valid)\n",
    "    trainds, valds = DefTrainValid(train_file, valid_file)\n",
    "    vec = vocab.Vectors('glove.twitter.27B.100d.txt', '/home/nithin/Git/Cryptic/GloVe-1.2')\n",
    "    txt_field.build_vocab(trainds, valds, max_size=200000, vectors=vec)\n",
    "    label_field.build_vocab(trainds)\n",
    "    traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), \n",
    "                                            batch_sizes=(512,1024), \n",
    "                                            sort_key=lambda x: len(x.Tweet), \n",
    "                                            device=-1, \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False)\n",
    "    train_batch_it = BatchGenerator(traindl, 'Tweet', 'Label') # use the wrapper to convert Batch to data\n",
    "    val_batch_it = BatchGenerator(valdl, 'Tweet', 'Label')\n",
    "    \n",
    "    vocab_size = len(txt_field.vocab)\n",
    "    embedding_dim = 100\n",
    "    n_hidden = 64\n",
    "    n_out = 3\n",
    "\n",
    "    m = ConcatPoolingGRUAdaptive(vocab_size, embedding_dim, n_hidden, n_out, trainds.fields['Tweet'].vocab.vectors)\n",
    "    opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n",
    "\n",
    "    fit(capital, model=m, train_dl=train_batch_it, val_dl=val_batch_it, loss_fn=F.nll_loss, opt=opt, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.embedding_dim,self.n_hidden,self.n_out,self.bidirectional = vocab_size, embedding_dim, n_hidden, n_out, bidirectional\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb.weight.data.copy_(pretrained_vec)\n",
    "        self.emb.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(self.n_hidden, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1) # batch size\n",
    "        seq = seq.transpose(0,1)\n",
    "        self.h = self.init_hidden(bs) # initialize hidden state of GRU\n",
    "        embs = self.emb(seq)\n",
    "        embs = embs.transpose(0,1)\n",
    "        embs = pack_padded_sequence(embs, lengths) # unpad\n",
    "        gru_out, self.h = self.gru(embs, self.h) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out) # pad the sequence to the max length in the batch\n",
    "        # since it is as classification problem, we will grab the last hidden state\n",
    "        outp = self.out(self.h[-1]) # self.h[-1] contains hidden state of last timestep\n",
    "#         return F.log_softmax(outp, dim=-1)\n",
    "        return F.log_softmax(outp)\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        if self.bidirectional:\n",
    "            return torch.zeros((2,batch_size,self.n_hidden))\n",
    "        else:\n",
    "            return torch.zeros((1,batch_size,self.n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatPoolingGRUAdaptive(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb.weight.data.copy_(pretrained_vec) # load pretrained vectors\n",
    "        self.emb.weight.requires_grad = False # make embedding non trainable\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            self.out = nn.Linear(self.n_hidden*2*2, self.n_out)\n",
    "        else:\n",
    "            self.out = nn.Linear(self.n_hidden*2, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1)\n",
    "        self.h = self.init_hidden(bs)\n",
    "        seq = seq.transpose(0,1)\n",
    "        embs = self.emb(seq)\n",
    "        embs = embs.transpose(0,1)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)        \n",
    "        \n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)        \n",
    "#         outp = self.out(torch.cat([self.h[-1],avg_pool,max_pool],dim=1))\n",
    "        outp = self.out(torch.cat([avg_pool,max_pool],dim=1))\n",
    "#         print(outp)\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        if self.bidirectional:\n",
    "            return torch.zeros((2,batch_size,self.n_hidden))\n",
    "        else:\n",
    "            return torch.zeros((1,batch_size,self.n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(capital, model, train_dl, val_dl, loss_fn, opt, epochs=3):\n",
    "    num_batch = len(train_dl)\n",
    "    senti_dict = {}\n",
    "    for epoch in tnrange(epochs):      \n",
    "        y_true_train = list()\n",
    "        y_pred_train = list()\n",
    "        total_loss_train = 0          \n",
    "        \n",
    "        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "        for (X,lengths),y in t:\n",
    "            t.set_description(\"Epoch {0}\".format(epoch))\n",
    "            lengths = lengths.cpu().numpy()\n",
    "                \n",
    "            opt.zero_grad()\n",
    "            pred = model(X, lengths)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item())\n",
    "            pred_idx = torch.max(pred, dim=1)[1]\n",
    "            \n",
    "            y_true_train += list(y.cpu().data.numpy())\n",
    "            y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "            total_loss_train += loss.item()\n",
    "            \n",
    "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        \n",
    "        if val_dl:\n",
    "            y_true_val = list()\n",
    "            y_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            for (X,lengths),y in tqdm_notebook(val_dl, leave=False):\n",
    "                pred = model(X, lengths.cpu().numpy())\n",
    "                loss = loss_fn(pred, y)\n",
    "                pred_idx = torch.max(pred, 1)[1]\n",
    "                y_true_val += list(y.cpu().data.numpy())\n",
    "                y_pred_val += list(pred_idx.cpu().data.numpy())\n",
    "                total_loss_val += loss.item()\n",
    "            valacc = accuracy_score(y_true_val, y_pred_val)\n",
    "            valloss = total_loss_val/len(val_dl)\n",
    "            y4senti = [i for i in y_pred_val if i!=1]\n",
    "            avg_senti = np.mean(y4senti)\n",
    "            if(math.isnan(avg_senti)):\n",
    "                avg_senti = 1.0\n",
    "            senti_dict[valacc] = avg_senti\n",
    "            \n",
    "            if(avg_senti<1.0):\n",
    "                new_amt = (avg_senti/2)*capital\n",
    "            elif(avg_senti==1.0):\n",
    "                new_amt = .5 * capital\n",
    "            else:\n",
    "                new_amt = (.5+((avg_senti - 1)/2))*capital\n",
    "            print(\"Epoch {0}: train_loss: {1:.4f} train_acc: {2:.4f} | val_loss: {3:.4f} val_acc: {4:.4f} avg_senti: {5:.4}\".format(epoch,train_loss,train_acc,valloss,valacc,avg_senti))\n",
    "            print(\"Original Capital : {0} New Capital : {1}\".format(capital,new_amt))\n",
    "        else:\n",
    "            print(\"Epoch {0}: train_loss: {1:.4f} train_acc: {2:.4f}\".format(epoch,train_loss,train_acc))\n",
    "    if(val_dl):\n",
    "        print(\"\\nMaximum accuracy and corresponding sentiment : \", max(senti_dict), senti_dict[max(senti_dict)])\n",
    "        if(avg_senti<1.0):\n",
    "                new_amt = (avg_senti/2)*capital\n",
    "                final_senti = 0 + ((avg_senti)/2)*100\n",
    "        elif(avg_senti==1.0):\n",
    "            new_amt = .5 * capital\n",
    "            final_senti = 50\n",
    "        else:\n",
    "            new_amt = (.5+((avg_senti - 1)/2))*capital\n",
    "            final_senti = 50 + ((avg_senti-1)/2)*100\n",
    "        print(\"Original Capital : {0} New Capital : {1}\".format(capital,new_amt))\n",
    "        print(\"Final Sentiment : \",final_senti)\n",
    "        return final_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c45d53fd0941bd83c5d94d4a14294b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 0.9037 train_acc: 0.6550 | val_loss: 0.8068 val_acc: 0.6749 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.8429 train_acc: 0.6552 | val_loss: 0.8011 val_acc: 0.6749 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss: 0.8202 train_acc: 0.6552 | val_loss: 0.8009 val_acc: 0.6749 avg_senti: 1.0\n",
      "Original Capital : 2500 New Capital : 1250.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss: 0.8035 train_acc: 0.6576 | val_loss: 0.7919 val_acc: 0.6756 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss: 0.7818 train_acc: 0.6683 | val_loss: 0.7790 val_acc: 0.6846 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss: 0.7497 train_acc: 0.6915 | val_loss: 0.7575 val_acc: 0.7093 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss: 0.6972 train_acc: 0.7216 | val_loss: 0.7615 val_acc: 0.6682 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss: 0.6699 train_acc: 0.7335 | val_loss: 0.7392 val_acc: 0.7055 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss: 0.6346 train_acc: 0.7415 | val_loss: 0.7214 val_acc: 0.7040 avg_senti: 2.0\n",
      "Original Capital : 2500 New Capital : 2500.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss: 0.6206 train_acc: 0.7562 | val_loss: 0.6943 val_acc: 0.7175 avg_senti: 1.988\n",
      "Original Capital : 2500 New Capital : 2484.6625766871166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss: 0.5893 train_acc: 0.7693 | val_loss: 0.6733 val_acc: 0.7377 avg_senti: 1.927\n",
      "Original Capital : 2500 New Capital : 2409.2741935483873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss: 0.5622 train_acc: 0.7758 | val_loss: 0.6732 val_acc: 0.7414 avg_senti: 1.867\n",
      "Original Capital : 2500 New Capital : 2333.8368580060423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss: 0.5378 train_acc: 0.7871 | val_loss: 0.6718 val_acc: 0.7526 avg_senti: 1.897\n",
      "Original Capital : 2500 New Capital : 2371.0073710073707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss: 0.5313 train_acc: 0.7845 | val_loss: 0.6460 val_acc: 0.7638 avg_senti: 1.772\n",
      "Original Capital : 2500 New Capital : 2215.277777777778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss: 0.5164 train_acc: 0.7971 | val_loss: 0.6565 val_acc: 0.7504 avg_senti: 1.763\n",
      "Original Capital : 2500 New Capital : 2204.0498442367602\n",
      "\n",
      "\n",
      "Maximum accuracy and corresponding sentiment :  0.7638266068759342 1.7722222222222221\n",
      "Original Capital : 2500 New Capital : 2204.0498442367602\n",
      "Final Sentiment :  88.1619937694704\n"
     ]
    }
   ],
   "source": [
    "finalSentiment = TwitterSentimentAnalysis(50,\"Bitcoin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
